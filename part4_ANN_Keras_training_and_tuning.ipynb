{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.stats import skew, boxcox\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_mae(labels,preds,lift=200):\n",
    "    return mean_absolute_error(np.exp(labels)-lift, np.exp(preds)-lift)\n",
    "\n",
    "# custom metric function for Keras\n",
    "def mae_log(y_true, y_pred): \n",
    "    return K.mean(K.abs((K.exp(y_pred)-200) - (K.exp(y_true)-200)))\n",
    "\n",
    "\n",
    "# Keras deosn't support sparse matrix. \n",
    "# The following functions are useful to split a large sparse matrix into smaller batches so they can be loaded into mem.\n",
    "def batch_generator(X, y, batch_size, shuffle):\n",
    "    number_of_batches = np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[batch_index,:].toarray()\n",
    "        y_batch = y[batch_index]\n",
    "        counter += 1\n",
    "        yield X_batch, y_batch\n",
    "        if (counter == number_of_batches):\n",
    "            if shuffle:\n",
    "                np.random.shuffle(sample_index)\n",
    "            counter = 0\n",
    "            \n",
    "def batch_generatorp(X, batch_size, shuffle):\n",
    "    number_of_batches = X.shape[0] / np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n",
    "        X_batch = X[batch_index, :].toarray()\n",
    "        counter += 1\n",
    "        yield X_batch\n",
    "        if (counter == number_of_batches):\n",
    "            counter = 0            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data finished in 2.915s\n",
      "Loading test data finished in 4.693s\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "start = time.time() \n",
    "train_data = pd.read_csv('../input/train.csv')\n",
    "train_size=train_data.shape[0]\n",
    "print (\"Loading train data finished in %0.3fs\" % (time.time() - start))        \n",
    "\n",
    "test_data = pd.read_csv('../input/test.csv')\n",
    "print (\"Loading test data finished in %0.3fs\" % (time.time() - start))         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge train and test\n",
    "\n",
    "This will save our time on duplicating logics for train and test and will also ensure the transformations applied on train and test are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data set created.\n"
     ]
    }
   ],
   "source": [
    "full_data=pd.concat([train_data,test_data])\n",
    "del( train_data, test_data)\n",
    "print (\"Full Data set created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_types = full_data.dtypes  \n",
    "cat_cols = list(data_types[data_types=='object'].index)\n",
    "num_cols = list(data_types[data_types=='int64'].index) + list(data_types[data_types=='float64'].index)\n",
    "\n",
    "id_col = 'id'\n",
    "target_col = 'loss'\n",
    "num_cols.remove('id')\n",
    "num_cols.remove('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric features\n",
    "\n",
    "Two preprocessings on numeric features are applied:\n",
    "\n",
    "   1. Apply box-cox transformations for skewed numeric features.\n",
    "\n",
    "   2. Scale numeric features so they will fall in the range between 0 and 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skewed_cols = full_data[num_cols].apply(lambda x: skew(x.dropna()))\n",
    "\n",
    "SSL = preprocessing.StandardScaler()\n",
    "skewed_cols = skewed_cols[skewed_cols > 0.25].index.values\n",
    "for skewed_col in skewed_cols:\n",
    "    full_data[skewed_col], lam = boxcox(full_data[skewed_col] + 1)\n",
    "for num_col in num_cols:\n",
    "    full_data[num_col] = SSL.fit_transform(full_data[num_col].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model OHE Coding\n",
    "####  Categorical features\n",
    "1. Label Encoding (Factorizing)\n",
    "2. One Hot Encoding (get dummies)\n",
    "\n",
    "OHE can be done by either get_dummies() from Pandas package or OneHotEncoder from SK-Learn package. \n",
    "\n",
    "* get_dummies is easier to implement (can be used directly on raw categorical features, i.e. strings, but it takes longer time and is not memory efficient.\n",
    "\n",
    "* OneHotEncoder requires the features being converted to numeric, which has already been done by LabelEncoder in previous step, and is much more efficient (7x faster).\n",
    "\n",
    "* The OHE's results are converted to a sparse matrix which uses way less memory as compared to dense matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label enconding finished in 33.628522 seconds\n"
     ]
    }
   ],
   "source": [
    "LBL = preprocessing.LabelEncoder()\n",
    "start=time.time()\n",
    "for cat_col in cat_cols:\n",
    "    full_data[cat_col] = LBL.fit_transform(full_data[cat_col])\n",
    "print ('Label enconding finished in %f seconds' % (time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot-encoding finished in 10.209203 seconds\n",
      "(313864, 1176)\n"
     ]
    }
   ],
   "source": [
    "OHE = preprocessing.OneHotEncoder(sparse=True)\n",
    "start=time.time()\n",
    "full_data_sparse=OHE.fit_transform(full_data[cat_cols])\n",
    "print 'One-hot-encoding finished in %f seconds' % (time.time()-start)\n",
    "print full_data_sparse.shape\n",
    "\n",
    "## it should be (313864, 1176)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313864, 1190)\n"
     ]
    }
   ],
   "source": [
    "lift = 200\n",
    "\n",
    "full_data_sparse = sparse.hstack((full_data_sparse\n",
    "                                  ,full_data[num_cols])\n",
    "                                 , format='csr'\n",
    "                                 )\n",
    "print full_data_sparse.shape\n",
    "train_x = full_data_sparse[:train_size]\n",
    "test_x = full_data_sparse[train_size:]\n",
    "train_y = np.log(full_data[:train_size].loss.values + lift)\n",
    "ID = full_data.id[:train_size].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_x, train_y, train_size=.80, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Kearas](https://keras.io)\n",
    "\n",
    "Keras is a high-level neural networks library, written in Python and capable of running on top of either TensorFlow or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU,LeakyReLU,ELU,ParametricSoftplus,ThresholdedReLU,SReLU\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Nadam\n",
    "from keras.regularizers import WeightRegularizer, ActivityRegularizer,l2, activity_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras starter\n",
    "\n",
    "Below is a quick starter example for creating a neural networks model using Keras. It covers the following aspects:\n",
    "1. multiple layers: 1 input, 1 hidden and 1 output\n",
    "2. normalization.\n",
    "3. dropout regularization.\n",
    "4. early stopping\n",
    "5. activate function\n",
    "6. optimizer\n",
    "7. batch training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For manual tunning of the neural networks model, I follow the instruction from [Tilii](https://www.kaggle.com/tilii7). The [link1](https://www.kaggle.com/mtinti/allstate-claims-severity/keras-starter-with-bagging-1111-84364/comments#143686) and [link2](https://www.kaggle.com/mtinti/allstate-claims-severity/keras-starter-with-bagging-1111-84364/comments#143693) are the original post from him.\n",
    "\n",
    "    Step 1: tune the size of each layer\n",
    "    Step 2: tune optimizer\n",
    "    Step 3: tune initialization function\n",
    "    Step 4: tune activation function\n",
    "    Step 5: tune dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_mae_log', patience=5, verbose=0, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath=\"weights.hdf5\", monitor='val_mae_log', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "def nn_model(params):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # input layer\n",
    "    model.add(Dense(params['input_size'], input_dim = params['input_dim']))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(params['input_drop_out']))\n",
    "    \n",
    "    # 1st hidden layer\n",
    "    model.add(Dense(params['hidden_size0']))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())    \n",
    "    model.add(Dropout(params['hidden_drop_out0']))\n",
    "    \n",
    "    # 2nd hidden layer\n",
    "    model.add(Dense(params['hidden_size1']))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())    \n",
    "    model.add(Dropout(params['hidden_drop_out1']))    \n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(loss = 'mae', metrics=[mae_log], optimizer = 'adadelta')\n",
    "    return(model)\n",
    "\n",
    "\n",
    "def nn_blend_data(parameters, train_x, train_y, test_x, fold, early_stopping_rounds=0, batch_size=128):\n",
    "    print (\"Blend %d estimators for %d folds\" % (len(parameters), fold))\n",
    "    skf = list(KFold(len(train_y), fold))\n",
    "    \n",
    "    scores = np.zeros ((len(skf),len(parameters)))\n",
    "    best_rounds = np.zeros ((len(skf),len(parameters)))\n",
    " \n",
    "    for j, nn_params in enumerate(parameters):\n",
    "        print (\"Model %d: %s\" %(j+1, nn_params))\n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], len(skf)))\n",
    "        for i, (train, val) in enumerate(skf):\n",
    "            print (\"Model %d fold %d\" %(j+1,i+1))\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x[train]\n",
    "            train_y_fold = train_y[train]\n",
    "            val_x_fold = train_x[val]\n",
    "            val_y_fold = train_y[val]\n",
    "\n",
    "            model = nn_model(nn_params)\n",
    "            print (model)\n",
    "            fit= model.fit_generator(generator=batch_generator(train_x_fold, train_y_fold, batch_size, True),\n",
    "                                     nb_epoch=60,\n",
    "                                     samples_per_epoch=train_x_fold.shape[0],\n",
    "                                     validation_data=(val_x_fold.todense(), val_y_fold),\n",
    "                                     verbose = 1,\n",
    "                                     callbacks=[\n",
    "#                                                 EarlyStopping(monitor='val_mae_log'\n",
    "#                                                               , patience=early_stopping_rounds, verbose=0, mode='auto'),\n",
    "                                                ModelCheckpoint(filepath=\"weights.hdf5\"\n",
    "                                                                , monitor='val_mae_log', \n",
    "                                                                verbose=0, save_best_only=True, mode='min')\n",
    "                                                ]\n",
    "                                     )\n",
    "            \n",
    "            model.load_weights(\"weights.hdf5\")\n",
    "            # Compile model (required to make predictions)\n",
    "            model.compile(loss = 'mae', metrics=[mae_log], optimizer = 'adadelta')\n",
    "\n",
    "            val_y_predict_fold = model.predict_generator(generator=batch_generatorp(val_x_fold, batch_size, True),\n",
    "                                        val_samples=val_x_fold.shape[0]\n",
    "                                     )\n",
    "            \n",
    "            score = log_mae(val_y_fold, val_y_predict_fold,200)\n",
    "            print (\"Score: \", score, mean_absolute_error(val_y_fold, val_y_predict_fold))\n",
    "            scores[i,j]=score\n",
    "\n",
    "            # Compile model (required to make predictions)\n",
    "            model.compile(loss = 'mae', metrics=[mae_log], optimizer = 'adadelta')            \n",
    "            print (\"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start))            \n",
    "   \n",
    "        print (\"Score for model %d is %f\" % (j+1,np.mean(scores[:,j])))\n",
    "    return (scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_parameters = [\n",
    "    {'input_size' :400 ,\n",
    "     'input_dim' : train_x.shape[1],\n",
    "     'input_drop_out' : 0.5 ,\n",
    "     'hidden_size0' : 150 ,\n",
    "     'hidden_drop_out0' :0.1,\n",
    "     'hidden_size1' : 20 ,\n",
    "     'hidden_drop_out1' :0.05,    \n",
    "     'learning_rate': 0.1}\n",
    "]\n",
    "\n",
    "(train_blend_x, test_blend_x, blend_scores,best_round) = nn_blend_data(nn_parameters, train_x, train_y, test_x,\n",
    "                                                         4,\n",
    "                                                         5)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
